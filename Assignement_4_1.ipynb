{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: A) The given dataset is a multiclass classification problem. Multiclass classification is a type of supervised learning problem in which we need to classify instances into one of three or more classes. In this dataset, we have 42 different types of diseases that can be predicted based on 132 parameters.\n",
    "\n",
    "For example, if we have a dataset of images of fruits and we want to classify them into different types of fruits such as apples, oranges, and bananas, then it would be a multiclass classification problem. Similarly, if we have a dataset of emails and we want to classify them into different categories such as spam, promotional, and personal, then it would also be a multiclass classification problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itching                 678\n",
       "skin_rash               786\n",
       "nodal_skin_eruptions    108\n",
       "continuous_sneezing     222\n",
       "shivering               108\n",
       "                       ... \n",
       "small_dents_in_nails    114\n",
       "inflammatory_nails      114\n",
       "blister                 114\n",
       "red_sore_around_nose    114\n",
       "yellow_crust_ooze       114\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv('./../Disease_data/Training.csv')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_df.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "\n",
    "# Separate categorical values from the \"Prognosis\" column\n",
    "prognosis = train_df['prognosis']\n",
    "train_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "\n",
    "# Count all columns containing 1 in their rows\n",
    "count_ones = train_df.sum(axis=0)\n",
    "\n",
    "count_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#train_df.drop(['Unnamed:133'], axis=1, inplace=True)\n",
    "# Create the model\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dtc.fit(train_df, prognosis)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_df = pd.read_csv('./../Disease_data/Testing.csv')\n",
    "test_prognosis = test_df['prognosis']\n",
    "test_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "dtc_predictions = dtc.predict(test_df)\n",
    "# Evaluate the accuracy of the model\n",
    "dtc_accuracy = accuracy_score(test_prognosis, dtc_predictions)\n",
    "print(\"Decision Tree Classifier accuracy:\", dtc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "# Train the model\n",
    "rfc.fit(train_df, prognosis)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "rfc_predictions = rfc.predict(test_df)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "rfc_accuracy = accuracy_score(test_prognosis, rfc_predictions)\n",
    "print(\"Random Forest Classifier accuracy:\", rfc_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(train_df, prognosis)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm.predict(test_df)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "svm_accuracy = accuracy_score(test_prognosis, svm_predictions)\n",
    "print(\"Support Vector Machine Classifier accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df_train = pd.read_csv('./../Disease_data/Training.csv')\n",
    "# Remove unnecessary columns\n",
    "df_train.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "df_test = pd.read_csv('./../Disease_data/Testing.csv')\n",
    "# Extract the symptoms columns\n",
    "symptoms_train = df_train.columns[:-1]\n",
    "symptoms_test = df_test.columns[:-1]\n",
    "\n",
    "# Create dummy variables for each symptom\n",
    "for symptom in symptoms_train:\n",
    "    df_train[symptom] = df_train[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "for symptom in symptoms_test:\n",
    "    df_test[symptom] = df_test[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Convert the disease column into categorical values\n",
    "df_train['prognosis'] = pd.Categorical(df_train['prognosis'])\n",
    "df_test['prognosis'] = pd.Categorical(df_test['prognosis'])\n",
    "\n",
    "# Split the dataset into X and y\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_rf = model.predict(df_test.drop('prognosis', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(df_test.drop('prognosis', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(df_test.drop('prognosis', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "Precision Score\n",
      "Accuracy (Random Forest): 98.81%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "Recall Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "F1 Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# accuracy score\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_rf)\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_lr)\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_svm)\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# precision score\n",
    "print('Precision Score')\n",
    "acc_rf = precision_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = precision_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = precision_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# recall score\n",
    "print('Recall Score')\n",
    "acc_rf = recall_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = recall_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = recall_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# f1 score\n",
    "print('F1 Score')\n",
    "acc_rf = f1_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = f1_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = f1_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m label_binarize\n\u001b[1;32m      6\u001b[0m \u001b[39m# Calculate the AUC-ROC curve\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(df_test))\n\u001b[1;32m      8\u001b[0m y_test_binary \u001b[39m=\u001b[39m label_binarize(df_test, classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(df_test))\n\u001b[1;32m      9\u001b[0m y_pred_proba \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict_proba(df_test)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Calculate the AUC-ROC curve\n",
    "n_classes = len(np.unique(df_test))\n",
    "y_test_binary = label_binarize(df_test, classes=np.unique(df_test))\n",
    "y_pred_proba = clf.predict_proba(df_test)\n",
    "fpr,tpr,thresholds = roc_curve(df_test, y_pred, pos_label=2) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the AUC-ROC curve\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
