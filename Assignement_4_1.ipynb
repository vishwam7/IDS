{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: A) The given dataset is a multiclass classification problem. Multiclass classification is a type of supervised learning problem in which we need to classify instances into one of three or more classes. In this dataset, we have 42 different types of diseases that can be predicted based on 132 parameters.\n",
    "\n",
    "For example, if we have a dataset of images of fruits and we want to classify them into different types of fruits such as apples, oranges, and bananas, then it would be a multiclass classification problem. Similarly, if we have a dataset of emails and we want to classify them into different categories such as spam, promotional, and personal, then it would also be a multiclass classification problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B)Popular algorithms for training a classification model:\n",
    "There are several popular algorithms that can be used for training a classification model on the given dataset. Here are three of them with their pros and cons:\n",
    "\n",
    "Random Forest Classifier:\n",
    "Pros:\n",
    "\n",
    "- Can handle large datasets with high dimensionality.\n",
    "- Does not overfit the data easily.\n",
    "- Can be used for feature selection.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Can be slow for large datasets.\n",
    "- Can produce biased results if there are imbalanced classes.\n",
    "- May not work well for datasets with noisy features.\n",
    "\n",
    "Logistic Regression:\n",
    "Pros:\n",
    "\n",
    "- Fast and easy to implement.\n",
    "- Works well for datasets with linearly separable features.\n",
    "- Can be regularized to avoid overfitting.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- May not work well for datasets with nonlinearly separable features.\n",
    "- Assumes that the relationship between the features and the target variable is linear.\n",
    "- Can produce biased results if there are imbalanced classes.\n",
    "\n",
    "Support Vector Machines:\n",
    "Pros:\n",
    "\n",
    "- Can handle datasets with nonlinearly separable features.\n",
    "- Can produce accurate results with high-dimensional datasets.\n",
    "- Can be used for feature selection.\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Can be slow for large datasets.\n",
    "- May not work well for datasets with noisy features.\n",
    "- Can produce biased results if there are imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itching                 678\n",
       "skin_rash               786\n",
       "nodal_skin_eruptions    108\n",
       "continuous_sneezing     222\n",
       "shivering               108\n",
       "                       ... \n",
       "small_dents_in_nails    114\n",
       "inflammatory_nails      114\n",
       "blister                 114\n",
       "red_sore_around_nose    114\n",
       "yellow_crust_ooze       114\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv('./Disease_data/Training.csv')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_df.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "\n",
    "# Separate categorical values from the \"Prognosis\" column\n",
    "prognosis = train_df['prognosis']\n",
    "train_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "\n",
    "# Count all columns containing 1 in their rows\n",
    "count_ones = train_df.sum(axis=0)\n",
    "\n",
    "count_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#train_df.drop(['Unnamed:133'], axis=1, inplace=True)\n",
    "# Create the model\n",
    "dtc = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "dtc.fit(train_df, prognosis)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_df = pd.read_csv('./Disease_data/Testing.csv')\n",
    "test_prognosis = test_df['prognosis']\n",
    "test_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "dtc_predictions = dtc.predict(test_df)\n",
    "# Evaluate the accuracy of the model\n",
    "dtc_accuracy = accuracy_score(test_prognosis, dtc_predictions)\n",
    "print(\"Decision Tree Classifier accuracy:\", dtc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the model\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "# Train the model\n",
    "rfc.fit(train_df, prognosis)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "rfc_predictions = rfc.predict(test_df)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "rfc_accuracy = accuracy_score(test_prognosis, rfc_predictions)\n",
    "print(\"Random Forest Classifier accuracy:\", rfc_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Classifier accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the model\n",
    "svm = SVC(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(train_df, prognosis)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm.predict(test_df)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "svm_accuracy = accuracy_score(test_prognosis, svm_predictions)\n",
    "print(\"Support Vector Machine Classifier accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C)Performance evaluation methods are important for assessing the effectiveness of machine learning models. These methods allow us to measure the accuracy and effectiveness of the model in making predictions.\n",
    "\n",
    "There are several common performance evaluation metrics used for classification models, including accuracy, precision, recall, and F1-score. Each of these metrics measures a different aspect of the model's performance and provides valuable insights into how well the model is performing.\n",
    "\n",
    "Accuracy measures the proportion of correctly classified instances out of the total number of instances in the dataset. Precision measures the proportion of true positives (correctly classified instances) out of the total number of instances classified as positive by the model. Recall measures the proportion of true positives out of the total number of instances that are actually positive. F1-score is the harmonic mean of precision and recall, and provides a balanced measure of both metrics.\n",
    "\n",
    "The significance of performance evaluation methods lies in their ability to help us identify the strengths and weaknesses of our models. By evaluating the model's performance on a test dataset, we can determine how well the model is likely to perform on new, unseen data. This information can be used to fine-tune the model, adjust its hyperparameters, or choose a different algorithm altogether.\n",
    "\n",
    "In addition, performance evaluation methods help us to compare the performance of different models, algorithms, or hyperparameters. By comparing the accuracy, precision, recall, and F1-score of different models, we can determine which one is likely to be the most effective for a given task.\n",
    "\n",
    "Overall, performance evaluation methods are essential for building effective machine learning models and ensuring that they perform well in real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df_train = pd.read_csv('./Disease_data/Training.csv')\n",
    "# Remove unnecessary columns\n",
    "df_train.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "df_test = pd.read_csv('./Disease_data/Testing.csv')\n",
    "# Extract the symptoms columns\n",
    "symptoms_train = df_train.columns[:-1]\n",
    "symptoms_test = df_test.columns[:-1]\n",
    "\n",
    "# Create dummy variables for each symptom\n",
    "for symptom in symptoms_train:\n",
    "    df_train[symptom] = df_train[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "for symptom in symptoms_test:\n",
    "    df_test[symptom] = df_test[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Convert the disease column into categorical values\n",
    "df_train['prognosis'] = pd.Categorical(df_train['prognosis'])\n",
    "df_test['prognosis'] = pd.Categorical(df_test['prognosis'])\n",
    "\n",
    "# Split the dataset into X and y\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_rf = model.predict(df_test.drop('prognosis', axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_pred_lr = model_lr.predict(df_test.drop('prognosis', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(df_test.drop('prognosis', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "Precision Score\n",
      "Accuracy (Random Forest): 98.81%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "Recall Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n",
      "F1 Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 100.00%\n",
      "Accuracy (Support Vector Machine): 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# accuracy score\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_rf)\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_lr)\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = accuracy_score(y_true, y_pred_svm)\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# precision score\n",
    "print('Precision Score')\n",
    "acc_rf = precision_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = precision_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = precision_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# recall score\n",
    "print('Recall Score')\n",
    "acc_rf = recall_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = recall_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = recall_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# f1 score\n",
    "print('F1 Score')\n",
    "acc_rf = f1_score(y_true, y_pred_rf, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = f1_score(y_true, y_pred_lr, average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "y_true = df_test['prognosis']\n",
    "acc_rf = f1_score(y_true, y_pred_svm, average='weighted')\n",
    "print('Accuracy (Support Vector Machine): {:.2f}%'.format(acc_rf * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
      "0        1          1                     1                    0          0   \n",
      "1        0          0                     0                    1          1   \n",
      "2        0          0                     0                    0          0   \n",
      "3        1          0                     0                    0          0   \n",
      "4        1          1                     0                    0          0   \n",
      "\n",
      "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
      "0       0           0             0        0                 0  ...   \n",
      "1       1           0             0        0                 0  ...   \n",
      "2       0           0             1        1                 1  ...   \n",
      "3       0           0             0        0                 0  ...   \n",
      "4       0           0             1        0                 0  ...   \n",
      "\n",
      "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
      "0           0         0             0                    0   \n",
      "1           0         0             0                    0   \n",
      "2           0         0             0                    0   \n",
      "3           0         0             0                    0   \n",
      "4           0         0             0                    0   \n",
      "\n",
      "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
      "0                     0                   0        0                     0   \n",
      "1                     0                   0        0                     0   \n",
      "2                     0                   0        0                     0   \n",
      "3                     0                   0        0                     0   \n",
      "4                     0                   0        0                     0   \n",
      "\n",
      "   yellow_crust_ooze            prognosis  \n",
      "0                  0     Fungal infection  \n",
      "1                  0              Allergy  \n",
      "2                  0                 GERD  \n",
      "3                  0  Chronic cholestasis  \n",
      "4                  0        Drug Reaction  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Calculate the AUC-ROC curve\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(df_test\u001b[39m.\u001b[39mhead())\n\u001b[0;32m----> 8\u001b[0m n_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(df_test))\n\u001b[1;32m      9\u001b[0m y_test_binary \u001b[39m=\u001b[39m label_binarize(df_test, classes\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(df_test))\n\u001b[1;32m     10\u001b[0m y_pred_proba \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(df_test)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ids_3/lib/python3.11/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ids_3/lib/python3.11/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Calculate the AUC-ROC curve\n",
    "print(df_test.head())\n",
    "n_classes = len(np.unique(df_test))\n",
    "y_test_binary = label_binarize(df_test, classes=np.unique(df_test))\n",
    "y_pred_proba = model.predict_proba(df_test)\n",
    "fpr,tpr,thresholds = roc_curve(df_test, y_pred, pos_label=2) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the AUC-ROC curve\n",
    "plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2: A)Hyperparameter tuning refers to the process of selecting the best possible values for the hyperparameters of a machine learning algorithm, which are the parameters set manually before the model is trained. These hyperparameters play a crucial role in determining the performance and behavior of the model. Some examples of hyperparameters include learning rate, regularization strength, and the number of hidden layers in a neural network.\n",
    "\n",
    "There are several methods for hyperparameter tuning, including:\n",
    "\n",
    "Grid search: This involves specifying a range of values for each hyperparameter and evaluating the model's performance on all possible combinations of these values. It can be computationally expensive but can lead to the best results if the range of values is well chosen.\n",
    "\n",
    "Random search: This involves randomly sampling hyperparameters from a specified distribution and evaluating the model's performance on each combination. It is less computationally expensive than grid search but may not always result in the best performance.\n",
    "\n",
    "Bayesian optimization: This involves using a probabilistic model to select the next set of hyperparameters to evaluate based on the results of previous evaluations. It can be more efficient than grid search or random search, but requires more expertise to implement.\n",
    "\n",
    "To use hyperparameter tuning to improve the performance of a classification model on a given dataset, we can use one of these methods to search for the best hyperparameters for a given algorithm. We can then use these optimal hyperparameters to train the model on the training dataset and evaluate its performance on the test dataset. This can lead to a more accurate and effective classification model that can be used to predict the prognosis of a given disease.\n",
    "\n",
    "Hyperparameter tuning is essential because hyperparameters significantly influence the model's accuracy and generalization performance. The process can help identify the optimal hyperparameters, leading to a better understanding of the underlying patterns in the data, avoiding overfitting or underfitting, and improving the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best score:  1.0\n",
      "                                         precision    recall  f1-score   support\n",
      "\n",
      "(vertigo) Paroymsal  Positional Vertigo       1.00      1.00      1.00         1\n",
      "                                   AIDS       1.00      1.00      1.00         1\n",
      "                                   Acne       1.00      1.00      1.00         1\n",
      "                    Alcoholic hepatitis       1.00      1.00      1.00         1\n",
      "                                Allergy       1.00      1.00      1.00         1\n",
      "                              Arthritis       1.00      1.00      1.00         1\n",
      "                       Bronchial Asthma       1.00      1.00      1.00         1\n",
      "                   Cervical spondylosis       1.00      1.00      1.00         1\n",
      "                            Chicken pox       1.00      1.00      1.00         1\n",
      "                    Chronic cholestasis       1.00      1.00      1.00         1\n",
      "                            Common Cold       1.00      1.00      1.00         1\n",
      "                                 Dengue       1.00      1.00      1.00         1\n",
      "                              Diabetes        1.00      1.00      1.00         1\n",
      "           Dimorphic hemmorhoids(piles)       1.00      1.00      1.00         1\n",
      "                          Drug Reaction       1.00      1.00      1.00         1\n",
      "                       Fungal infection       1.00      0.50      0.67         2\n",
      "                                   GERD       1.00      1.00      1.00         1\n",
      "                        Gastroenteritis       1.00      1.00      1.00         1\n",
      "                           Heart attack       1.00      1.00      1.00         1\n",
      "                            Hepatitis B       1.00      1.00      1.00         1\n",
      "                            Hepatitis C       1.00      1.00      1.00         1\n",
      "                            Hepatitis D       1.00      1.00      1.00         1\n",
      "                            Hepatitis E       1.00      1.00      1.00         1\n",
      "                          Hypertension        1.00      1.00      1.00         1\n",
      "                        Hyperthyroidism       1.00      1.00      1.00         1\n",
      "                           Hypoglycemia       1.00      1.00      1.00         1\n",
      "                         Hypothyroidism       1.00      1.00      1.00         1\n",
      "                               Impetigo       0.50      1.00      0.67         1\n",
      "                               Jaundice       1.00      1.00      1.00         1\n",
      "                                Malaria       1.00      1.00      1.00         1\n",
      "                               Migraine       1.00      1.00      1.00         1\n",
      "                        Osteoarthristis       1.00      1.00      1.00         1\n",
      "           Paralysis (brain hemorrhage)       1.00      1.00      1.00         1\n",
      "                    Peptic ulcer diseae       1.00      1.00      1.00         1\n",
      "                              Pneumonia       1.00      1.00      1.00         1\n",
      "                              Psoriasis       1.00      1.00      1.00         1\n",
      "                           Tuberculosis       1.00      1.00      1.00         1\n",
      "                                Typhoid       1.00      1.00      1.00         1\n",
      "                Urinary tract infection       1.00      1.00      1.00         1\n",
      "                         Varicose veins       1.00      1.00      1.00         1\n",
      "                            hepatitis A       1.00      1.00      1.00         1\n",
      "\n",
      "                               accuracy                           0.98        42\n",
      "                              macro avg       0.99      0.99      0.98        42\n",
      "                           weighted avg       0.99      0.98      0.98        42\n",
      "\n",
      "Accuracy:  0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the training and testing data\n",
    "train_data = pd.read_csv('./Disease_data/Training.csv')\n",
    "train_data.drop('Unnamed: 133', axis=1, inplace=True)\n",
    "test_data = pd.read_csv('./Disease_data/Testing.csv')\n",
    "\n",
    "# Split the training data into features (X) and labels (y)\n",
    "X_train = train_data.drop('prognosis', axis=1)\n",
    "y_train = train_data['prognosis']\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Define the classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "# print(X_train.isna().sum())\n",
    "X_train.fillna(0, inplace=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and their score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to train the model\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "X_test = test_data.drop('prognosis', axis=1)\n",
    "y_test = test_data['prognosis']\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Print the classification report and accuracy score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
