{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score,accuracy_score,precision_score,recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consider the below dataset. Applying Knowledge to the field of Medical Science and making the task of Physician easy is the main purpose of this dataset. This dataset has 132 parameters on which 42 different types of diseases can be predicted. Based on the dataset, now answer the following questions:(code + theory)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)What type of problem is the given dataset? Explain with examples?\n",
    "\n",
    "    The given dataset is a classification problem, where the goal is to predict which of the 42 diseases a patient is likely to have based on their symptoms and demographic information. This is a supervised learning problem because the dataset includes labeled examples of patients with known diagnoses.\n",
    "\n",
    "    Classification problems involve predicting discrete categorical values, such as the presence or absence of a disease, the type of a disease, or the outcome of a medical procedure. They are commonly used in healthcare to aid in diagnosis and treatment decisions, as well as in medical research to identify risk factors for different conditions.\n",
    "\n",
    "    Examples of other classification problems in healthcare include:\n",
    "\n",
    "    -Identifying cancerous cells in a biopsy sample based on their morphology and other characteristics.\n",
    "\n",
    "    -Predicting the likelihood of a patient developing complications after surgery based on their medical history and demographic information.\n",
    "\n",
    "    -Classifying patients with heart disease based on their symptoms and diagnostic tests.\n",
    "\n",
    "    -Identifying patients who are at high risk of developing diabetes based on their lifestyle and genetic factors.\n",
    "\n",
    "    -Predicting which patients are likely to respond well to a particular medication based on their genetic profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "itching                 678\n",
       "skin_rash               786\n",
       "nodal_skin_eruptions    108\n",
       "continuous_sneezing     222\n",
       "shivering               108\n",
       "                       ... \n",
       "small_dents_in_nails    114\n",
       "inflammatory_nails      114\n",
       "blister                 114\n",
       "red_sore_around_nose    114\n",
       "yellow_crust_ooze       114\n",
       "Length: 132, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load the dataset\n",
    "Disease_df = pd.read_csv('./Disease_data/Training.csv')\n",
    "\n",
    "# Remove unnecessary columns\n",
    "Disease_df.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "\n",
    "# Separate categorical values from the \"Prognosis\" column\n",
    "prognosis = Disease_df['prognosis']\n",
    "Disease_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "\n",
    "# Count all columns containing 1 in their rows\n",
    "count_ones = Disease_df.sum(axis=0)\n",
    "\n",
    "count_ones\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)What are some popular algorithms we have introduced in our class that can be used for training a classification model on the given dataset? Compare their pros and cons. \n",
    "\n",
    "\n",
    "    There are several popular algorithms that can be used to train a classification model on the given dataset. Some of the algorithms we have introduced in class include logistic regression, decision trees, random forests, and Decision Tree Classifiers (SVMs). Here are some pros and cons of each algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df_train = pd.read_csv('./Disease_data/Training.csv')\n",
    "# Remove unnecessary columns\n",
    "df_train.drop(['Unnamed: 133'], axis=1, inplace=True)\n",
    "df_test = pd.read_csv('./Disease_data/Testing.csv')\n",
    "# Extract the symptoms columns\n",
    "symptoms_train = df_train.columns[:-1]\n",
    "symptoms_test = df_test.columns[:-1]\n",
    "\n",
    "# Create dummy variables for each symptom\n",
    "for symptom in symptoms_train:\n",
    "    df_train[symptom] = df_train[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "for symptom in symptoms_test:\n",
    "    df_test[symptom] = df_test[symptom].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Convert the disease column into categorical values\n",
    "df_train['prognosis'] = pd.Categorical(df_train['prognosis'])\n",
    "df_test['prognosis'] = pd.Categorical(df_test['prognosis'])\n",
    "\n",
    "# Split the dataset into X and y\n",
    "X_train = df_train.iloc[:, :-1]\n",
    "y_train = df_train.iloc[:, -1]\n",
    "X_test = df_test.iloc[:, :-1]\n",
    "y_test = df_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    -Logistic Regression:\n",
    "    --Pros: Simple and easy to interpret, works well with small datasets and linearly separable problems.\n",
    "    --Cons: Assumes linear relationship between features and outcome, may not perform well when features are not linearly separable.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred_LR = LR.predict(X_train)\n",
    "print(\"Accuracy:\",accuracy_score(y_train, y_pred_LR))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Decision Trees:\n",
    "    --Pros: Easy to interpret and visualize, can handle both categorical and numerical features, works well with non-linear problems.\n",
    "    --Cons: Can be prone to overfitting, can be sensitive to small changes in the data and may lead to different trees.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(Disease_df, prognosis)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_df = pd.read_csv('./Disease_data/Testing.csv')\n",
    "test_prognosis = test_df['prognosis']\n",
    "test_df.drop(['prognosis'], axis=1, inplace=True)\n",
    "dtc_predictions = clf.predict(test_df)\n",
    "# Evaluate the accuracy of the model\n",
    "dtc_accuracy = accuracy_score(test_prognosis, dtc_predictions)\n",
    "print(\"Decision Tree Classifier accuracy:\", dtc_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    -Random Forests:\n",
    "    --Pros: Reduces overfitting and variance, works well with high-dimensional datasets, can handle both categorical and numerical features.\n",
    "    --Cons: Can be computationally expensive, may not be as easy to interpret as a single decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier accuracy: 0.9761904761904762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "# Train the model\n",
    "rfc.fit(Disease_df, prognosis)\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "rfc_predictions = rfc.predict(test_df)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "rfc_accuracy = accuracy_score(test_prognosis, rfc_predictions)\n",
    "print(\"Random Forest Classifier accuracy:\", rfc_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii)How do you evaluate the performance of a classification model? Discuss different evaluation metrics and explain their significance.?\n",
    "\n",
    "    Confusion Matrix: A confusion matrix is a table that summarizes the performance of a classification model by comparing the predicted and actual values of the target variable. It is used to calculate other metrics like accuracy, precision, recall, and F1 score. The four possible outcomes of a binary classification problem are true positives, false positives, true negatives, and false negatives.\n",
    "\n",
    "    Accuracy: Accuracy measures the percentage of correctly classified instances out of the total number of instances in the dataset. It is a simple metric that is easy to interpret, but it can be misleading if the dataset is imbalanced.\n",
    "\n",
    "    Precision: Precision measures the proportion of correctly classified positive instances out of all instances that are predicted as positive. It is a useful metric when the cost of false positives is high, such as in medical diagnosis.\n",
    "\n",
    "    Recall: Recall measures the proportion of correctly classified positive instances out of all actual positive instances. It is a useful metric when the cost of false negatives is high, such as in identifying cancer patients.\n",
    "\n",
    "    F1 score: The F1 score is the harmonic mean of precision and recall. It is a useful metric when both precision and recall are important.\n",
    "\n",
    "    Area Under the ROC Curve (AUC-ROC): AUC-ROC is a measure of the trade-off between true positives and false positives. It plots the true positive rate (TPR) against the false positive rate (FPR) at various classification thresholds. AUC-ROC values range from 0 to 1, where a higher value indicates better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Random Forest): 97.62%\n",
      "(42,) (4920,)\n",
      "Accuracy (Logistic Regression): 2.38%\n",
      "Accuracy (Decision Tree Classifier): 97.62%\n",
      "Precision Score\n",
      "Accuracy (Random Forest): 98.81%\n",
      "Accuracy (Logistic Regression): 0.48%\n",
      "Accuracy (Decision Tree Classifier): 98.81%\n",
      "Recall Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "(4920,)\n",
      "Accuracy (Logistic Regression): 2.38%\n",
      "Accuracy (Decision Tree Classifier): 97.62%\n",
      "F1 Score\n",
      "Accuracy (Random Forest): 97.62%\n",
      "Accuracy (Logistic Regression): 0.79%\n",
      "Accuracy (Decision Tree Classifier): 97.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_df  = pd.read_csv('./Disease_data/Testing.csv')\n",
    "y_true = test_df['prognosis']\n",
    "acc_rf = accuracy_score(y_true, rfc_predictions)\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "print(y_true.shape,y_pred_LR.shape)\n",
    "acc_rf = accuracy_score(y_true, y_pred_LR[:42])\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = accuracy_score(y_true, dtc_predictions)\n",
    "print('Accuracy (Decision Tree Classifier): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# precision score\n",
    "print('Precision Score')\n",
    "acc_rf = precision_score(y_true, rfc_predictions, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = precision_score(y_true, y_pred_LR[:42], average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = precision_score(y_true, dtc_predictions, average='weighted')\n",
    "print('Accuracy (Decision Tree Classifier): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# recall score\n",
    "print('Recall Score')\n",
    "acc_rf = recall_score(y_true, rfc_predictions, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "print(y_pred_LR.shape[:42])\n",
    "acc_rf = recall_score(y_true, y_pred_LR[:42], average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = recall_score(y_true, dtc_predictions, average='weighted')\n",
    "print('Accuracy (Decision Tree Classifier): {:.2f}%'.format(acc_rf * 100))\n",
    "\n",
    "# f1 score\n",
    "print('F1 Score')\n",
    "acc_rf = f1_score(y_true, rfc_predictions, average='weighted')\n",
    "print('Accuracy (Random Forest): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = f1_score(y_true, y_pred_LR[:42], average='weighted')\n",
    "print('Accuracy (Logistic Regression): {:.2f}%'.format(acc_rf * 100))\n",
    "acc_rf = f1_score(y_true, dtc_predictions, average='weighted')\n",
    "print('Accuracy (Decision Tree Classifier): {:.2f}%'.format(acc_rf * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the dataset of Question 1 and answer the following questions based on the dataset:(code+theory)\n",
    "\n",
    "    What is hyperparameter tuning? How can you use it to improve the performance of a classification model on the given dataset? 07\n",
    "\n",
    "    Can you implement a neural network model to classify the given dataset? Discuss the architecture and hyperparameters of the model. 06\n",
    "\n",
    "    How can you handle class imbalance in the given dataset? Discuss different techniques and their effectiveness. 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_features': 'log2', 'max_depth': None, 'criterion': 'gini'}\n",
      "Best accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    #'min_samples_split': none,\n",
    "    #'min_samples_leaf': random.randint(1, 5),\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Instantiate the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Instantiate the randomized search object\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
    "\n",
    "# Fit the randomized search object to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding accuracy score\n",
    "print(\"Best hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best accuracy score:\", random_search.best_score_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You are given a dataset containing information about customer churn for a telecommunications company. The dataset has a mixture of continuous and categorical variables. You have been asked to build a logistic regression model to predict which customers are likely to churn. (18 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService   \n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No  \\\n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection   \n",
       "0  No phone service             DSL             No  ...               No  \\\n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling   \n",
       "0          No          No              No  Month-to-month              Yes  \\\n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "Tele_df = pd.read_csv('./WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "Tele_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i)Explain what is regularization in machine learning> Why is it important?\n",
    "\n",
    "    Regularization is a machine learning strategy that avoids the model being overfit to the training data, which can result in subpar performance on new data. Overfitting occurs when a model gets too complicated and learns the training data, including noise, too well, preventing it from generalizing to new data. Regularization techniques successfully reduce the complexity of the model by adding extra restrictions to the model parameters to prevent overfitting by lowering the parameters towards zero.\n",
    "\n",
    "    Regularization is crucial because it helps the model perform better when applied to new data. Without regularization, a predictive model can match training data too well while underperforming on fresh data, which would be counterproductive. Regularization can also increase model stability by decreasing the model's sensitivity to minute changes in the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ii)\tDiscuss the L1 and L2 regularization techniques. What is the difference between them?\n",
    "\n",
    "    L1 and L2 regularization are two popular subtypes of regularization algorithms. The penalty term added by L1 regularization, commonly referred to as Lasso regularization, is inversely correlated with the absolute value of the model weights. This kind of regularization frequently results in sparse models with some weights set to zero, which effectively eliminates pointless features from the model. The penalty term added by L2 regularization, sometimes referred to as Ridge regularization, is inversely proportional to the square of the model weights. All of the features are often employed in these regularized models, but the weights are smaller and more uniformly distributed.\n",
    "    \n",
    "    The sort of penalty term applied to the objective function distinguishes L1 regularization from L2 regularization. As L1 regularization employs the weights' absolute values, it frequently results in sparse models with some weights set to zero. The square of the weights is used for L2 regularization, which tends to result in models with smaller and more uniformly distributed weights. Moreover, compared to L2 regularization, L1 regularization is more resistant to outliers in the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(iii) Implement a logistic regression model on a given dataset and tune the regularization hyperparameter. Discuss the effect of regularization on the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
       "       'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
       "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
       "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
       "       'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for the colums look for categorial values\n",
    "Tele_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService   \n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No  \\\n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection   \n",
       "0  No phone service             DSL             No  ...               No  \\\n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling   \n",
       "0          No          No              No  Month-to-month              Yes  \\\n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
       "0           Electronic check          29.85         29.85    No  \n",
       "1               Mailed check          56.95        1889.5    No  \n",
       "2               Mailed check          53.85        108.15   Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
       "4           Electronic check          70.70        151.65   Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tele_df.head()\n",
    "# As we can gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', \n",
    "# 'InternetService','OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "#'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.bool_"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tele_df = pd.get_dummies(Tele_df, columns=['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                                 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "                                 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod'])\n",
    "Tele_df.head()\n",
    "type(Tele_df['gender_Male'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "columns_data = Tele_df.columns\n",
    "columns_data\n",
    "\n",
    "failed = []\n",
    "\n",
    "for _ in columns_data:\n",
    "    if isinstance(Tele_df[_][1], str) and Tele_df[_][1] in ['Yes', 'No']:\n",
    "        Tele_df[_] = Tele_df[_].map({'Yes': 1, 'No': 0})\n",
    "    elif isinstance(Tele_df[_][1], np.bool_):\n",
    "        Tele_df[_] = Tele_df[_].map({True: 1, False: 0})\n",
    "    else:\n",
    "        failed.append(_)\n",
    "\n",
    "#print(isinstance(Tele_df['gender_Female'][1],np.bool_))\n",
    "#print(type(Tele_df['gender_Female'][1]))\n",
    "# Tele_df['Churn'] = Tele_df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "# Tele_df['gender_Female'] = Tele_df['gender_Female'].map({'True': 1, 'False': 0})\n",
    "# Tele_df['Partner_no'] = Tele_df['Partner_no'].map({'True': 1, 'False': 0})\n",
    "# Tele_df['Partner_yes'] = Tele_df['Partner_yes'].map({'True': 1, 'False': 0})\n",
    "# Tele_df['StreamingMovies_Yes'] = Tele_df['gender_Female'].map({'True': 1, 'False': 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>Partner_No</th>\n",
       "      <th>Partner_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>StreamingMovies_Yes</th>\n",
       "      <th>Contract_Month-to-month</th>\n",
       "      <th>Contract_One year</th>\n",
       "      <th>Contract_Two year</th>\n",
       "      <th>PaperlessBilling_No</th>\n",
       "      <th>PaperlessBilling_Yes</th>\n",
       "      <th>PaymentMethod_Bank transfer (automatic)</th>\n",
       "      <th>PaymentMethod_Credit card (automatic)</th>\n",
       "      <th>PaymentMethod_Electronic check</th>\n",
       "      <th>PaymentMethod_Mailed check</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  SeniorCitizen  tenure  MonthlyCharges TotalCharges  Churn   \n",
       "0  7590-VHVEG              0       1           29.85        29.85      0  \\\n",
       "1  5575-GNVDE              0      34           56.95       1889.5      0   \n",
       "2  3668-QPYBK              0       2           53.85       108.15      1   \n",
       "3  7795-CFOCW              0      45           42.30      1840.75      0   \n",
       "4  9237-HQITU              0       2           70.70       151.65      1   \n",
       "\n",
       "   gender_Female  gender_Male  Partner_No  Partner_Yes  ...   \n",
       "0              1            0           0            1  ...  \\\n",
       "1              0            1           1            0  ...   \n",
       "2              0            1           1            0  ...   \n",
       "3              0            1           1            0  ...   \n",
       "4              1            0           1            0  ...   \n",
       "\n",
       "   StreamingMovies_Yes  Contract_Month-to-month  Contract_One year   \n",
       "0                    0                        1                  0  \\\n",
       "1                    0                        0                  1   \n",
       "2                    0                        1                  0   \n",
       "3                    0                        0                  1   \n",
       "4                    0                        1                  0   \n",
       "\n",
       "   Contract_Two year  PaperlessBilling_No  PaperlessBilling_Yes   \n",
       "0                  0                    0                     1  \\\n",
       "1                  0                    1                     0   \n",
       "2                  0                    0                     1   \n",
       "3                  0                    1                     0   \n",
       "4                  0                    0                     1   \n",
       "\n",
       "   PaymentMethod_Bank transfer (automatic)   \n",
       "0                                        0  \\\n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   PaymentMethod_Credit card (automatic)  PaymentMethod_Electronic check   \n",
       "0                                      0                               1  \\\n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PaymentMethod_Mailed check  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           1  \n",
       "3                           0  \n",
       "4                           0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we can see we have converted all the categorical data into 1's and 0's for easy datamanipulation\n",
    "Tele_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for col in Tele_df.columns:\n",
    "    \n",
    "    # Check if the column data type is object or bool\n",
    "    if Tele_df[col].dtype == 'object' or Tele_df[col].dtype == 'bool':\n",
    "        \n",
    "        # Convert non-numeric data to numeric data using label encoder\n",
    "        Tele_df[col] = le.fit_transform(Tele_df[col].astype(str))\n",
    "        \n",
    "x_data = Tele_df.drop(['Churn','customerID'], axis=1)\n",
    "y_data = Tele_df['Churn']\n",
    "\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create logistic regression object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[ 1.83849892e-01 -3.81740137e-02  6.27243721e-03  5.16874567e-05\n",
      "  -6.63448051e-02 -1.14142931e-01 -1.11903498e-01 -6.85842378e-02\n",
      "   2.37019505e-02 -2.04189686e-01  2.58728275e-02 -2.06360563e-01\n",
      "  -2.68440073e-01  2.58728275e-02  6.20795100e-02 -3.77363737e-01\n",
      "   3.11220138e-01 -1.14344137e-01  2.16987958e-01 -1.14344137e-01\n",
      "  -2.83131557e-01  5.09517810e-02 -1.14344137e-01 -1.17095380e-01\n",
      "  -5.28610836e-03 -1.14344137e-01 -6.08574905e-02  2.06681038e-01\n",
      "  -1.14344137e-01 -2.72824637e-01 -1.28232824e-01 -1.14344137e-01\n",
      "   6.20892248e-02 -1.69877626e-01 -1.14344137e-01  1.03734027e-01\n",
      "   2.97726474e-01 -1.80232887e-01 -2.97981323e-01 -2.90966865e-01\n",
      "   1.10479129e-01 -1.00212499e-01 -1.59473368e-01  2.60458820e-01\n",
      "  -1.81260688e-01]]\n",
      "Mean squared error: 0.18\n",
      "Variance score: 0.06\n",
      "0.8168914123491838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train,y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = logreg.predict(x_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', logreg.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "        % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "print('Accuracy',accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.001 Accuracy: 0.8062455642299503\n",
      "C =  0.01 Accuracy: 0.8147622427253371\n",
      "C =  0.1 Accuracy: 0.815471965933286\n",
      "C =  1 Accuracy: 0.8168914123491838\n",
      "C =  10 Accuracy: 0.815471965933286\n",
      "C =  100 Accuracy: 0.815471965933286\n"
     ]
    }
   ],
   "source": [
    "#Tunning our Regularaization Parameters \n",
    "for c in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    model = LogisticRegression(penalty='l2', C=c)\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"C = \", c, \"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain the bias-variance tradeoff in machine learning? How can regularization help to balance it?\n",
    "\n",
    "\n",
    "    The bias-variance tradeoff is a fundamental concept in machine learning that deals with the problem of overfitting and underfitting in models. The tradeoff is a result of the need to balance the complexity of a model against its ability to accurately generalize to new data.\n",
    "\n",
    "    Bias is the discrepancy between the target variable's actual values and the predicted model predictions. It is a model's condensing premise about the data it is trained on. Strong data assumptions are made by a model with considerable bias, which might result in underfitting. When a model is too simplistic to accurately represent the underlying structure of the data, underfitting occurs, leading to subpar performance on both the training and test sets of data.\n",
    "\n",
    "    Contrarily, variation is the degree to which the model's predictions differ as a result of being trained on various subsets of the training data. A model with a high variance will overfit since it is sensitive to the data noise. Overfitting is a condition in which a model performs well on training data but poorly on test data because it is overly complex and tries to fit the noise in the data rather than the underlying structure.\n",
    "\n",
    "    A model must strike the ideal balance between bias and variance in order to perform as well as feasible on new data. The bias-variance tradeoff refers to this. High bias models have low variance, whereas low bias models have high variance. A model that has the ideal balance of bias and variance will perform well on both the training data and the test data.\n",
    "\n",
    "    By lowering the variance in the model's predictions, regularization can also assist a model perform better when it comes to generalization. Regularization assists in preventing the model from forgetting the training data and fitting noise in the data by keeping the model's complexity low. As a result, the model has a better chance of generalizing to new data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suppose you have a dataset consisting of the following 8 points in a two-dimensional space: {(2, 10), (2, 5), (8, 4), (5, 8), (7, 5), (6, 4), (1, 2), (4, 9)}. (20 points) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\tUse the K-Means Algorithm with K=2 to cluster the data points into two clusters. Show your work step-by-step, including the initial random selection of cluster centers, the calculation of the distances between data points and cluster centers, and the reassignment of data points to clusters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Labels:  [0. 0. 1. 0. 1. 1. 1. 0.]\n",
      "Centroids:  [[3 8]\n",
      " [5 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the dataset\n",
    "X = np.array([(2, 10), (2, 5), (8, 4), (5, 8), (7, 5), (6, 4), (1, 2), (4, 9)])\n",
    "\n",
    "# Set the number of clusters\n",
    "k = 2\n",
    "\n",
    "# Initialize the centroids randomly\n",
    "centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "\n",
    "# Initialize the old centroids to zeros\n",
    "old_centroids = np.zeros(centroids.shape)\n",
    "\n",
    "# Initialize the cluster labels\n",
    "cluster_labels = np.zeros(len(X))\n",
    "\n",
    "# Loop until the centroids no longer move\n",
    "while np.linalg.norm(centroids - old_centroids) != 0:\n",
    "\n",
    "    # Assign each data point to the closest centroid\n",
    "    for i in range(len(X)):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        cluster_labels[i] = np.argmin(distances)\n",
    "\n",
    "    # Update the centroids\n",
    "    old_centroids = np.copy(centroids)\n",
    "    for i in range(k):\n",
    "        points = [X[j] for j in range(len(X)) if cluster_labels[j] == i]\n",
    "        centroids[i] = np.mean(points, axis=0)\n",
    "\n",
    "print(\"Cluster Labels: \", cluster_labels)\n",
    "print(\"Centroids: \", centroids)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)\tCalculate the Cluster Purity of the resulting clusters from (part a), using the ground truth labels {(2, 10), (2, 5), (1, 2), (4, 9)} as belonging to Cluster 1 and the rest belonging to\n",
    "Cluster 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1 Purity:  0.75\n",
      "Cluster 2 Purity:  0.25\n"
     ]
    }
   ],
   "source": [
    "# Define the ground truth labels\n",
    "ground_truth = np.array([(2, 10), (2, 5), (1, 2), (4, 9)])\n",
    "ground_truth_labels = np.zeros(len(X))\n",
    "\n",
    "# Assign the ground truth points to Cluster 1\n",
    "for i in range(len(X)):\n",
    "    if np.any(np.all(X[i] == ground_truth, axis=1)):\n",
    "        ground_truth_labels[i] = 1\n",
    "\n",
    "# Calculate the cluster purity\n",
    "cluster_1_indices = np.where(cluster_labels == 0)[0]\n",
    "cluster_1_ground_truth_labels = ground_truth_labels[cluster_1_indices]\n",
    "cluster_1_purity = np.sum(cluster_1_ground_truth_labels) / len(cluster_1_ground_truth_labels)\n",
    "\n",
    "cluster_2_indices = np.where(cluster_labels == 1)[0]\n",
    "cluster_2_ground_truth_labels = ground_truth_labels[cluster_2_indices]\n",
    "cluster_2_purity = np.sum(cluster_2_ground_truth_labels) / len(cluster_2_ground_truth_labels)\n",
    "\n",
    "print(\"Cluster 1 Purity: \", cluster_1_purity)\n",
    "print(\"Cluster 2 Purity: \", cluster_2_purity)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)\tUse the Elbow Method to determine the optimal number of clusters for the dataset from part a). Plot the Within-Cluster Sum of Squares (WCSS) for K=1 to K=7 and identify the \"elbow\" point where the rate of decrease in WCSS slows down significantly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the Within-Cluster Sum of Squares (WCSS) for each k value\n",
    "wcss = []\n",
    "for k in range(1, 8):\n",
    "    kmeans = KMeans(n_clusters=k, init='random')\n",
    "    kmeans.fit(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the WCSS vs. k values\n",
    "plt.plot(range(1, 8), wcss)\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d)\tUse Density-Based Clustering with a radius of 2 and a minimum density of 3 to cluster the dataset from part a). Show the resulting clusters and explain the advantages and disadvantages of Density-Based Clustering compared to K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1  0 -1  0  0 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Create DBSCAN object\n",
    "dbscan = DBSCAN(eps=2, min_samples=3)\n",
    "\n",
    "# Fit and predict clusters\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Print resulting clusters\n",
    "print(clusters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Suppose you are working as a data scientist for a financial services company. You are tasked with building a machine learning model to predict whether a customer will default on their loan payments or not. You have been provided with a dataset containing information about past customers, including their credit history, income, debt, and other demographic information. (20 points)\n",
    "\n",
    "Outline the steps you would take to review the data before building the model. What are some common issues you might encounter, and how would you address them? Please be specific.\n",
    "\n",
    "After reviewing the data, you decide to use a logistic regression model to predict loan defaults. You train the model on the dataset and evaluate its performance using\n",
    "\n",
    "cross-validation. However, you find that the model is performing poorly and is not able to predict defaults accurately. What steps would you take to debug the model and improve its performance?\n",
    "\n",
    "In addition to the logistic regression model, you also decide to try a decision tree model to predict defaults. After training the model on the dataset, you review its performance and find that it is much better than the logistic regression model. However, upon closer inspection, you realize that the decision tree is overfitting the data and is not able to generalize well to new data. What steps would you take to address the overfitting and improve the generalization performance of the model?\n",
    "\n",
    "Suppose you are given a new dataset that contains additional features that were not present in the original dataset. What steps would you take to review the new data and incorporate the new features into your model? What are some potential issues that you might encounter, and how would you address them?\n",
    "\n",
    "In addition to the new features, you also discover that the dataset contains some missing values and outliers. What steps would you take to handle missing values and outliers in the data, and how might these steps affect the performance of your model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>location</th>\n",
       "      <th>email</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>income</th>\n",
       "      <th>debt</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maurice</td>\n",
       "      <td>Hansen</td>\n",
       "      <td>Port Melissa</td>\n",
       "      <td>lewisadam@example.net</td>\n",
       "      <td>0.129351</td>\n",
       "      <td>42004.504429</td>\n",
       "      <td>6567.554626</td>\n",
       "      <td>33.082666</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison</td>\n",
       "      <td>Walker</td>\n",
       "      <td>East Soniaberg</td>\n",
       "      <td>jocelyn21@example.net</td>\n",
       "      <td>1.353309</td>\n",
       "      <td>38702.060209</td>\n",
       "      <td>13241.896161</td>\n",
       "      <td>34.360064</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philip</td>\n",
       "      <td>Ramos</td>\n",
       "      <td>Michaelchester</td>\n",
       "      <td>tina72@example.net</td>\n",
       "      <td>1.552804</td>\n",
       "      <td>46746.015071</td>\n",
       "      <td>11480.052074</td>\n",
       "      <td>36.339176</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne</td>\n",
       "      <td>Perry</td>\n",
       "      <td>Hernandezville</td>\n",
       "      <td>norma49@example.org</td>\n",
       "      <td>-0.620193</td>\n",
       "      <td>40799.681690</td>\n",
       "      <td>9105.181818</td>\n",
       "      <td>23.466386</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scott</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>New Jeffreyfort</td>\n",
       "      <td>thomasanderson@example.net</td>\n",
       "      <td>-0.465170</td>\n",
       "      <td>46394.326448</td>\n",
       "      <td>9379.625474</td>\n",
       "      <td>32.103298</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_name last_name         location                       email   \n",
       "0    Maurice    Hansen     Port Melissa       lewisadam@example.net  \\\n",
       "1    Allison    Walker   East Soniaberg       jocelyn21@example.net   \n",
       "2     Philip     Ramos   Michaelchester          tina72@example.net   \n",
       "3    Suzanne     Perry   Hernandezville         norma49@example.org   \n",
       "4      Scott    Nelson  New Jeffreyfort  thomasanderson@example.net   \n",
       "\n",
       "   credit_history        income          debt        age gender  default  \n",
       "0        0.129351  42004.504429   6567.554626  33.082666      F        0  \n",
       "1        1.353309  38702.060209  13241.896161  34.360064      F        0  \n",
       "2        1.552804  46746.015071  11480.052074  36.339176      F        1  \n",
       "3       -0.620193  40799.681690   9105.181818  23.466386      M        0  \n",
       "4       -0.465170  46394.326448   9379.625474  32.103298      M        0  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_default_df = pd.read_csv(\"./loan_default_dataset.csv\")\n",
    "Loan_default_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first_name        0\n",
       "last_name         0\n",
       "location          0\n",
       "email             0\n",
       "credit_history    0\n",
       "income            0\n",
       "debt              0\n",
       "age               0\n",
       "gender            0\n",
       "default           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Null_values = Loan_default_df.isna().sum()\n",
    "Null_values\n",
    "#As we can see no null values are found in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['first_name', 'last_name', 'location', 'email', 'credit_history',\n",
       "       'income', 'debt', 'age', 'gender', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loan_default_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping some columns to reduce the features, that doesn;t effect the data , such as lastname and location\n",
    "X = Loan_default_df.drop(['first_name','email','last_name','location'],axis=1)\n",
    "Loan_default_df.head()\n",
    "Y = Loan_default_df['default']\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categorical data into binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dummies = pd.get_dummies(X['gender'], prefix='gender')\n",
    "\n",
    "# add the new columns to the dataframe\n",
    "X = pd.concat([X, gender_dummies], axis=1)\n",
    "\n",
    "# drop the original 'Gender' column\n",
    "X.drop('gender', axis=1, inplace=True)\n",
    "X['gender_F'] = X['gender_F'].astype(int)\n",
    "X['gender_M'] = X['gender_M'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750,)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(X,Y, random_state=42)\n",
    "#x_train.shape\n",
    "\n",
    "y_train.shape\n",
    "#x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(x_train,y_train)\n",
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.808\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 score: 0.0\n",
      "ROC AUC: 0.5\n",
      "Confusion matrix:\n",
      " [[202   0]\n",
      " [ 48   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy = LR_model.score(x_test, y_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1 score:', f1)\n",
    "print('ROC AUC:', roc_auc)\n",
    "print('Confusion matrix:\\n', confusion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can the accuracy for our model is pretty good, i.e 80%, but as we can the Precision score is not good, and we can also in out confusion matrix, True negative are pretty high which means our model is not predicting correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Decision Tree classifier for more appropriate Evaluation\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "DT_model.fit(x_train,y_train)\n",
    "y_pred = DT_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1 score: 1.00\n",
      "ROC AUC: 1.00\n",
      "Confusion matrix:\n",
      " [[202   0]\n",
      " [  0  48]]\n"
     ]
    }
   ],
   "source": [
    "acurracy = accuracy_score(y_test,y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 score: {:.2f}\".format(f1))\n",
    "print(\"ROC AUC: {:.2f}\".format(roc_auc))\n",
    "print(\"Confusion matrix:\\n\", confusion)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-The accuracy of the model is 0.81, which means that it correctly predicted the class label for 81% of the instances in the test set.\n",
    "\n",
    "-The precision of the model is 1.00, which means that it correctly predicted all instances of the positive class and did not predict any instances of the negative class as positive.\n",
    "\n",
    "-The recall of the model is 1.00, which means that it correctly identified all instances of the positive class.\n",
    "\n",
    "-The F1 score of the model is 1.00, which is the harmonic mean of precision and recall, and represents a balance between the two metrics.\n",
    "\n",
    "-The ROC AUC of the model is 1.00, which means that it has perfect discrimination between the two classes.\n",
    "\n",
    "-The confusion matrix shows that there were 202 true negatives (TN), 0 false positives (FP), 0 false negatives (FN), and 48 true positives (TP). This suggests that the model performed very well and was able to correctly predict all instances of the positive class.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250,) (250,)\n",
      "(250,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous-multioutput and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/Assignment4.ipynb Cell 39\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro%20to%20Data%20Science%20Assignment4/IDS/Assignment4.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(y_test[:\u001b[39m250\u001b[39m]\u001b[39m.\u001b[39mshape,y_train_pred[:\u001b[39m250\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro%20to%20Data%20Science%20Assignment4/IDS/Assignment4.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(y_test\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro%20to%20Data%20Science%20Assignment4/IDS/Assignment4.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining_acc set score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(accuracy_score(x_test,y_train_pred[:\u001b[39m250\u001b[39;49m])))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro%20to%20Data%20Science%20Assignment4/IDS/Assignment4.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest_acc set score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(accuracy_score(y_test,y_test_pred)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/adityasugandhi/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro%20to%20Data%20Science%20Assignment4/IDS/Assignment4.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest_acc set score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(DT_model\u001b[39m.\u001b[39mscore(x_test, y_test)))\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-FloridaStateUniversity/Introduction_To_DataScience/Intro to Data Science Assignment4/IDS/.conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and binary targets"
     ]
    }
   ],
   "source": [
    "#Checking if our model is overfitting\n",
    "y_train_pred  = DT_model.predict(x_train)\n",
    "y_test_pred = DT_model.predict(x_test)\n",
    "print(y_test[:250].shape,y_train_pred[:250].shape)\n",
    "print(y_test.shape)\n",
    "print(\"Training_acc set score: {:.3f}\".format(accuracy_score(x_test,y_train_pred[:250])))\n",
    "print(\"Test_acc set score: {:.3f}\".format(accuracy_score(y_test,y_test_pred)))\n",
    "print(\"Test_acc set score: {:.3f}\".format(DT_model.score(x_test, y_test)))\n",
    "print(\"Training set score: {:.3f}\".format(DT_model.score(x_train, y_train)))\n",
    "#print(\"Test set score: {:.3f}\".format(DT_model.score(x_test, y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you are given a new dataset that contains additional features that were not present in the original dataset. What steps would you take to review the new data and incorporate the new features into your model? What are some potential issues that you might encounter, and how would you address them?\n",
    "\n",
    "Potential Issues that we might encounter\n",
    "\n",
    "Overfitting: If the new features are not relevant to the target variable, or if they introduce noise into the data, the model may overfit the training data and perform poorly on new data.\n",
    "\n",
    "Multicollinearity: If the new features are highly correlated with existing features, they may introduce multicollinearity into the model, which can cause instability in the model's coefficients and make it difficult to interpret the relative importance of each feature.\n",
    "\n",
    "Missing data: If the new features contain missing data, this can cause problems for the model. One approach to dealing with missing data is to impute the missing values using techniques such as mean imputation or regression imputation, but this can introduce bias into the model if the imputation method is not appropriate.\n",
    "\n",
    "Outliers: If the new features contain outliers, this can also cause problems for the model. Outliers can skew the distribution of the data and make it difficult for the model to capture the underlying patterns in the data.\n",
    "\n",
    "To address these potential issues, it is important to carefully review the new features and assess their relevance to the target variable. It may also be necessary to preprocess the data using techniques such as normalization, standardization, or feature selection to address issues such as multicollinearity and outliers. Finally, it is important to evaluate the performance of the model on both the training and validation data to ensure that it is generalizing well to new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the new features, you also discover that the dataset contains some missing values and outliers. What steps would you take to handle missing values and outliers in the data, and how might these steps affect the performance of your model?\n",
    "\n",
    "\n",
    "    We can perform the following for identifiying missing values as wel as handling them,:\n",
    "\n",
    "    -Identifying missing values: Check the dataset for any missing values. This can be done using functions such as isnull() or info() in Python.\n",
    "\n",
    "    -Handling missing values: There are several ways to handle missing values, including:\n",
    "\n",
    "    -Dropping missing values: If the number of missing values is small, you can simply drop those rows or columns that contain missing values. However, if the number of missing values is large, dropping those rows or columns may lead to a significant loss of information.\n",
    "\n",
    "    -Imputing missing values: You can also impute missing values by replacing them with a mean, median, or mode value of that column or by using predictive models to estimate the missing values.\n",
    "\n",
    "    -Identifying outliers: Outliers are data points that are significantly different from the other data points in the dataset. You can identify outliers using statistical methods such as the Z-score or the IQR method.\n",
    "\n",
    "    -Handling outliers: There are several ways to handle outliers, including:\n",
    "\n",
    "    -Removing outliers: You can simply remove the outliers from the dataset. However, this may lead to a loss of information, and it may not always be appropriate to remove outliers.\n",
    "\n",
    "    -Winsorization: Winsorization is a method in which the extreme values are replaced with less extreme values. For example, you can replace the outliers with the 5th or 95th percentile of that column.\n",
    "\n",
    "    -Binning: You can also bin the data into discrete categories based on the range of the values. This can help in reducing the impact of outliers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Write a short essay discussing the importance of reviewing data and debugging models in the machine learning workflow. Provide examples of how failure to review data or debug models can lead to poor performance and inaccurate predictions, and discuss how these issues can be prevented.\n",
    "\n",
    "\n",
    "    In the machine learning workflow, reviewing data and debugging models are critical steps that ensure the accuracy and reliability of the model. Neglecting these steps can lead to poor performance and inaccurate predictions, which can have significant consequences, especially in high-stakes industries such as healthcare and finance.\n",
    "\n",
    "    Data review involves examining the quality and completeness of the data, identifying missing values, outliers, and potential biases. Failure to review data can result in models that are trained on incomplete or biased data, leading to inaccurate predictions. For instance, suppose a model is trained to predict patient outcomes in a hospital using only data from one department. In that case, the model may not generalize well to patients in other departments or hospitals, resulting in poor performance.\n",
    "\n",
    "    Debugging models is also essential in ensuring that the model is working as intended. Debugging involves identifying and correcting errors in the model's code, selecting appropriate hyperparameters, and testing the model's performance. Failing to debug the model can result in incorrect predictions and can be costly, especially in high-stakes applications.\n",
    "\n",
    "    For example, suppose a model is trained to predict credit risk in a financial institution, but the model is not working correctly due to an error in the code. In that case, the model may approve loans that are likely to default, resulting in significant financial losses for the institution.\n",
    "\n",
    "    To prevent these issues, it is essential to review the data thoroughly, identify potential biases and errors, and ensure that the data is complete and representative. Debugging the model involves testing the model on a separate validation set, tuning hyperparameters, and identifying and correcting errors in the code. By conducting these steps meticulously, machine learning practitioners can ensure that their models are accurate, reliable, and perform well in real-world scenarios\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
